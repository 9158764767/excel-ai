import io
import os
from typing import List

from fastapi import FastAPI, UploadFile, Form, Request, HTTPException
from fastapi.responses import HTMLResponse, StreamingResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from openai import OpenAI


# Determine which OpenAI model to use. Defaults to `gpt-4o`, which supports the Code Interpreter tool.
OPENAI_MODEL = os.environ.get("OPENAI_MODEL", "gpt-4o")


def _get_app_key() -> str:
    """Helper to retrieve the application key from environment for auth."""
    return os.environ.get("APP_KEY", "")


app = FastAPI(title="Excel AI Pro")

# Mount a static directory in case assets are added in the future. Right now it is empty.
static_dir = os.path.join(os.path.dirname(__file__), "static")
app.mount("/static", StaticFiles(directory=static_dir), name="static")

# Jinja2 templating for serving the HTML UI.
templates = Jinja2Templates(directory=os.path.join(os.path.dirname(__file__), "templates"))

# Instantiate the OpenAI client using the API key from the environment. If not provided, an exception will be thrown
# when a request is attempted.
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))


# System prompt instructing the model to act as a data analyst and provide EDA where appropriate.
SYSTEM_PROMPT = (
    "You are a precise data analyst. Always use the Code Interpreter tool to open the uploaded file as a pandas "
    "DataFrame. Then perform the requested task succinctly. If cleaning or transforming data, also export a cleaned "
    "Excel named 'result.xlsx'. Provide exploratory data analysis including summary statistics, missingness, and "
    "correlations. If charts would help illustrate the data, save them as PNG images. Keep outputs concise and "
    "structured."
)


@app.get("/", response_class=HTMLResponse)
async def home(request: Request) -> HTMLResponse:
    """
    Serve the single-page application that allows users to upload a spreadsheet and select a task.

    Args:
        request: The incoming HTTP request.

    Returns:
        A templated HTML response.
    """
    return templates.TemplateResponse("index.html", {"request": request})


@app.get("/health")
async def health_check() -> JSONResponse:
    """Simple health check endpoint."""
    return JSONResponse({"status": "ok"})


@app.post("/analyze")
async def analyze_excel(
    request: Request,
    task: str = Form("summary"),
    file: UploadFile = None,
) -> JSONResponse:
    """
    Accept an uploaded spreadsheet and run it through OpenAI's Code Interpreter tool based on the specified task.

    If `REQUIRE_APP_KEY` is set to "1" in the environment, the endpoint enforces a simple API key check via the
    `X-App-Key` header. If authentication fails, a 401 error is returned. Otherwise, the file is uploaded to OpenAI,
    a response with the Code Interpreter tool is created, and the resulting outputs are parsed. If a cleaned Excel
    workbook is generated by the model, it is streamed back to the client; otherwise, a JSON summary is returned.

    Args:
        request: The incoming HTTP request (used for header inspection).
        task: The analysis task requested by the user. Defaults to "summary".
        file: The uploaded spreadsheet file.

    Returns:
        A streaming response containing a cleaned Excel workbook or a JSON summary with optional artifact count.
    """
    if file is None:
        raise HTTPException(status_code=400, detail="No file provided")

    # Enforce optional API key authentication.
    require_key = os.environ.get("REQUIRE_APP_KEY")
    if require_key == "1":
        header_key = request.headers.get("X-App-Key")
        if not header_key or header_key != _get_app_key():
            raise HTTPException(status_code=401, detail="Unauthorized")

    # Read file contents into memory. UploadFile uses async so we await it.
    file_bytes = await file.read()

    # Upload the file to OpenAI so the Code Interpreter tool can access it. Purpose "assistants" is used for
    # temporary storage associated with tool runs.
    uploaded = client.files.create(
        file=(file.filename, io.BytesIO(file_bytes)),
        purpose="assistants",
    )

    # Construct the messages for the OpenAI responses API. The system prompt defines the analyst persona,
    # and the user message instructs the specific task to perform.
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {
            "role": "user",
            "content": [
                {"type": "input_text", "text": f"Task: {task}. Use the uploaded file."},
                {"type": "input_file", "file_id": uploaded.id},
            ],
        },
    ]

    # Invoke the Responses API with the Code Interpreter tool. The `tools` field instructs the model to use the
    # specified tool when analyzing the file.
    response = client.responses.create(
        model=OPENAI_MODEL,
        input=messages,
        tools=[{"type": "code_interpreter"}],
    )

    # Parse the output to collect message text and any generated artifacts (files).
    summary_chunks: List[str] = []
    artifact_ids: List[str] = []

    for item in getattr(response, "output", []) or []:
        if getattr(item, "type", None) == "message":
            for part in getattr(item, "content", []) or []:
                if getattr(part, "type", None) == "output_text":
                    summary_chunks.append(getattr(part, "text", ""))
        elif getattr(item, "type", None) == "tool_output":
            for part in getattr(item, "content", []) or []:
                if getattr(part, "type", None) == "output_file":
                    fid = getattr(part, "file_id", None)
                    if fid:
                        artifact_ids.append(fid)

    summary_text = "\n\n".join(summary_chunks).strip() or "(No summary text returned.)"

    # Inspect artifacts: if an Excel file is produced, stream it back. Otherwise, return JSON with summary and count.
    selected_content: bytes | None = None
    selected_name: str | None = None
    for fid in artifact_ids:
        try:
            meta = client.files.retrieve(fid)
            filename = getattr(meta, "filename", None) or getattr(meta, "name", None) or "artifact.bin"
        except Exception:
            filename = "artifact.bin"
        try:
            content_stream = client.files.content(fid)
            data = content_stream.read()
        except Exception:
            data = None
        if data and filename.lower().endswith((".xlsx", ".xls")):
            selected_content = data
            selected_name = filename
            break

    # If a cleaned workbook was created, stream it with the summary in a header. Otherwise return JSON.
    if selected_content is not None:
        headers = {"x-summary": summary_text[:800]}
        return StreamingResponse(
            io.BytesIO(selected_content),
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers=headers,
        )

    return JSONResponse({
        "summary": summary_text,
        "artifact_count": len(artifact_ids),
        "note": "If a cleaned Excel was produced, it will be streamed directly.",
    })
